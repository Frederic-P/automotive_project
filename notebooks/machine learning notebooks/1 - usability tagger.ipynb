{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USABILITY TAGGER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../../utils')\n",
    "import config_handling as conf\n",
    "from database import Database\n",
    "from file_io import path_handler\n",
    "from cnn_helpers import preprocess_image, system_override"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config = conf.read_config('../../config/automotive.conf.ini')\n",
    "config.read('config.ini')\n",
    "connection_type = config['settings']['connection']\n",
    "user = config[connection_type]['user']\n",
    "pw = config[connection_type]['pw']\n",
    "host = config[connection_type]['host']\n",
    "db = config[connection_type]['db']\n",
    "port = config[connection_type].getint('port')\n",
    "db = Database(host,\n",
    "              port,\n",
    "              user,\n",
    "              pw,\n",
    "              db\n",
    "              )\n",
    "db.connect()\n",
    "\n",
    "# Image directory\n",
    "basedir = config['settings']['image_directory']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Problem framing. \n",
    "Not all images are usefull to be part of the full classification pipeline, as such we want to get rid of these before we commence training. In some cases it's immediately apparent if an image is useful or not; pictures of keyfobs, tire thread, car seats... none of these help in the final goal of this project (i.e. identifying a car brand and model by exterior pictures. ) Some images clearly show the outside of a car, but show it in ways that'd not be helpful either: extreme close-ups or opened doors. These too are considered unusable. Finally there are photographs where the car is 'cropped' off to one or more sides. As a general rule these too will be flagged as unusable. \n",
    "\n",
    "## 2 Data.\n",
    "No training data was available that could teach a model if an image is useful or not. To quickly generate this data, a Flask app was written which is part of this repo in `/flash angle tagger`. This tagger provides an HTML interface where crappy - vs non-crappy images could easily be marked by a click button or keyboard shortcut. If an image is considered to be usable, it'd receive one of eight possible angle-tags. The topic of angle tagging is discussed in notebook `2 - angle tagging.ipynb`. \n",
    "\n",
    "For an image to be considered usable, it had to fulfill the following requirements: \n",
    "1) The car should be fully visible on the image. (No cropping)\n",
    "2) Obstruction is allowed, but should be kept within a reasonable amount. \n",
    "3) Doors, lids,... should be closed. \n",
    "4) Only exterior photographs are allowed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 A sample of unusable images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images_as_grid(imseries, title, n=4): \n",
    "    \"\"\"\n",
    "    creates a grid of n*n images by randomply picking n**2 images\n",
    "    from a series object (imseries) and plots them into the notebook. \n",
    "    \"\"\"\n",
    "    samplesize = n**2\n",
    "    chosen = imseries.sample(samplesize)\n",
    "    fig, axes = plt.subplots(n, n, figsize=(12, 12))\n",
    "    axes = axes.flatten()\n",
    "    i = 0\n",
    "    for image in chosen: \n",
    "        img = Image.open(image)\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].axis('off')\n",
    "        i+=1\n",
    "    fig.suptitle(title, fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\" SELECT\n",
    "                angletags.*,\n",
    "                images.image_path\n",
    "            FROM angletags \n",
    "            JOIN images ON images.id = angletags.image_id\n",
    "            WHERE \n",
    "                angletags.manual_annotation = 1 AND\n",
    "                angletags.angle = \"crappy\"; \n",
    "        \"\"\"\n",
    "unusable_data = db.execute_query(query)\n",
    "crappy_df = pd.DataFrame(unusable_data)\n",
    "crappy_df['image_path'] = crappy_df['image_path'].apply(lambda x: path_handler(basedir, x))\n",
    "plot_images_as_grid(crappy_df['image_path'], 'Grid of unusable images', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 A sample of usable images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\" SELECT\n",
    "                angletags.*,\n",
    "                images.image_path\n",
    "            FROM angletags \n",
    "            JOIN images ON images.id = angletags.image_id\n",
    "            WHERE \n",
    "                angletags.manual_annotation = 1 AND\n",
    "                angletags.angle <> \"crappy\"; \n",
    "        \"\"\"\n",
    "usable_data = db.execute_query(query)\n",
    "good_df = pd.DataFrame(usable_data)\n",
    "good_df['image_path'] = good_df['image_path'].apply(lambda x: path_handler(basedir, x))\n",
    "plot_images_as_grid(good_df['image_path'], 'Grid of good images',5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two grids above of 5 by 5 each illustrate the outcome applying all rules. About 20.000 images where manually tagged. The outcome of this proces is as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT\n",
    "                COUNT(*) AS f,\n",
    "                CASE\n",
    "                    WHEN angletags.angle = 'crappy' THEN 'crappy'\n",
    "                    ELSE 'non-crappy'\n",
    "                END AS usability\n",
    "            FROM angletags\n",
    "            WHERE angletags.manual_annotation = 1\n",
    "            GROUP BY usability\n",
    "            HAVING usability IN ('crappy', 'non-crappy')\n",
    "        \"\"\"\n",
    "angle_distribution_data = db.execute_query(query)\n",
    "angle_df = pd.DataFrame(angle_distribution_data)\n",
    "plt.bar(angle_df['usability'], angle_df['f'])\n",
    "plt.title('Image usability of manually tagged data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model training: \n",
    "We do not know how many images we need to tag for a model to pick up the differences between a usable and unusable image. To figure this out, we'll go through our manually tagged data and gradually increase the amount of data our model is trained on. \n",
    "\n",
    "To do this, we'll start with splitting our data and keep a validation set to the side. This validation set will be used by every trained model to measure how well it performs. \n",
    "\n",
    "The part of the data that's not in the validation set will be used to train models, each model will see more data than the previous one. Our trainingsdata will start with seeing 5% of the data and grow with 5% increments each time. For every round of model training, we'll try to measure how precise the model is. We know that we've fed sufficient training data to our model if two consecutive training sets do not show any performance gain any longer. \n",
    "\n",
    "At this stage we also have our bounding boxes available, so we'll see if this makes the model perform better or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_override()\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    device = 'GPU'\n",
    "    tf.config.set_visible_devices(physical_devices[0], 'GPU')\n",
    "else:\n",
    "    device = 'CPU'\n",
    "\n",
    "# Print the device being used\n",
    "print(f\"Using {device} for deep learning.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data from MYSQL and into a pandas DataFrame: \n",
    "tagged_data_query = \"\"\" SELECT\n",
    "                angletags.angle,\n",
    "                images.image_path, \n",
    "                images.yolobox_top_left_x AS x1,\n",
    "                images.yolobox_top_left_y AS y1,\n",
    "                images.yolobox_bottom_right_x AS x2,\n",
    "                images.yolobox_bottom_right_y AS y2\n",
    "            FROM angletags \n",
    "            JOIN images ON images.id = angletags.image_id\n",
    "            WHERE \n",
    "                angletags.manual_annotation = 1;\n",
    "        \"\"\"\n",
    "tagged_usability_data = db.execute_query(tagged_data_query)\n",
    "tagged_df = pd.DataFrame(tagged_usability_data)\n",
    "#add the fully qualified paths: \n",
    "tagged_df['image_path'] = tagged_df['image_path'].apply(lambda x: path_handler(basedir, x))\n",
    "#where no bounding box was made, the database holds NULL, (pandas NaN); \n",
    "# so fillna() with sentinel value\n",
    "tagged_df = tagged_df.fillna(-1)\n",
    "#enforce integers for bbox coords: \n",
    "tagged_df[['x1', 'y1', 'x2', 'y2']] = tagged_df[['x1', 'y1', 'x2', 'y2']].astype(int)\n",
    "# encode an y:\n",
    "tagged_df['usable_image'] = tagged_df['angle'].apply(lambda x: 0 if x == 'crappy' else 1)\n",
    "# drop angle:\n",
    "tagged_df.drop(columns=['angle'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a part of your data out to use as validation. Use a stratified split on the 'angle' column\n",
    "#    YES... I know we already use angle, but it's not a problem; any angle that is not crappy is considered good.\n",
    "#    so your stratified split woudl more or less be the same anyway. \n",
    "rs = 42\n",
    "X = tagged_df.drop(columns=['usable_image'])\n",
    "y = tagged_df['usable_image']\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.2, random_state=rs, stratify=tagged_df['angle'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the X_validation and y_validation will not be used for training, only for evaluating every loop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "imsize_single_dim = 128    #how big is one side of the image. \n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "model_dir = os.path.join(os.getcwd(), '../../models/bin_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(imsize_single_dim, imsize_single_dim, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(imsize_single_dim, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(imsize_single_dim*2, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "binary_model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start the experiment with data volume; also experiment with using or dismissing bounding boxes.\n",
    "## TQDM is useless here, but this experiment should last: ((sum(fractions)/0.05) * 2) * first loop time \n",
    "# you could theoretically speed this up by not always resampling from X_train and y_train and just add 0.05 each time\n",
    "# but I want to have the variety (in the small sample sises). \n",
    "fractions = np.linspace(0.05, 0.99999, 10)\n",
    "fractions = [0.9999]\n",
    "use_bboxes = [True, False]\n",
    "epochs = [5, 10]\n",
    "imsizess_on_one_dim = [64, 128]\n",
    "#TODO make epoch and image size a variable to in this improvised grid search. \n",
    "\n",
    "\n",
    "for fraction in fractions:\n",
    "    # Take fraction% of the data from X_train and y_train\n",
    "    X_train_sample, _, y_train_sample, _ = train_test_split(\n",
    "        X_train, y_train, \n",
    "        test_size=1-fraction,\n",
    "        random_state=rs\n",
    "    ) \n",
    "    for use_bounding_boxes in use_bboxes:\n",
    "        name = f\"fracsize={fraction}__bbox={use_bounding_boxes}__imsize_sqrd={imsize_single_dim}.keras\"\n",
    "        images = []\n",
    "        for _, row in X_train_sample.iterrows():\n",
    "            #print(row)\n",
    "            bbox = (row['x1'], row['y1'], row['x2'], row['y2'])\n",
    "            img = preprocess_image(row['image_path'], use_bounding_boxes, bbox, imsize_single_dim)\n",
    "            images.append(img)\n",
    "        images = np.array(images)  # you can't pass a list, but need to pass np array or a tensor!!: ((https://stackoverflow.com/questions/63527536/passing-a-python-list-to-keras-model-fit))\n",
    "        y_train_sample = np.array(y_train_sample)  # just to be sure. \n",
    "        binary_model.fit(\n",
    "                            images, \n",
    "                            y_train_sample, \n",
    "                            epochs=epochs, \n",
    "                            batch_size=batch_size, \n",
    "                            validation_split=0.2\n",
    "                        )\n",
    "        saveto = os.path.join(model_dir, name)\n",
    "        binary_model.save(saveto)\n",
    "        with open(os.path.join(model_dir, 'model_notes.txt'), 'a+') as logfile: \n",
    "            logfile.write(f\"{saveto}, {len(images)}, {epochs}, {imsize_single_dim}, {batch_size}\\n\")\n",
    "            logfile.flush()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os('poweroff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "automotive_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
