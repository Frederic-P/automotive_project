{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brand predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-10 12:50:23.846867: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1736513423.867374    5160 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1736513423.874067    5160 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-10 12:50:23.896058: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import cv2\n",
    "import sys\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "sys.path.append('../../utils')\n",
    "import config_handling as conf\n",
    "from database import Database\n",
    "from file_io import path_handler\n",
    "import matplotlib.image as mpimg\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytorch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adam\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytorch\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytorch'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ensure TensorFlow compatibility for CNN-based feature extraction and classifiers\n",
    "import tensorflow as tf\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_bbox = True    #run the model/training with bounding boxes when available? \n",
    "\n",
    "#set the learning device: gpu or cpu: \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"       #force CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection established\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load configuration\n",
    "config = conf.read_config('../../config/automotive.conf.ini')\n",
    "config.read('config.ini')\n",
    "connection_type = config['settings']['connection']\n",
    "user = config[connection_type]['user']\n",
    "pw = config[connection_type]['pw']\n",
    "host = config[connection_type]['host']\n",
    "db = config[connection_type]['db']\n",
    "port = config[connection_type].getint('port')\n",
    "db = Database(host,\n",
    "              port,\n",
    "              user,\n",
    "              pw,\n",
    "              db\n",
    "              )\n",
    "db.connect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Image directory\n",
    "basedir = config['settings']['image_directory']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_brands = db.execute_query('SELECT distinct(brand) FROM listings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "brands = pd.DataFrame(distinct_brands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Brand tags \n",
    "BRANDS = brands['brand']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bbox_to_ints(df):\n",
    "    df = df.copy()\n",
    "    for col in ['yolobox_top_left_x', 'yolobox_top_left_y', 'yolobox_bottom_right_x', 'yolobox_bottom_right_y']:\n",
    "        df[col] = df[col].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query labeled and unlabeled data\n",
    "tags = db.execute_query(\"\"\"SELECT\n",
    "                            images.yolobox_top_left_x, \n",
    "                            images.yolobox_top_left_y, \n",
    "                            images.yolobox_bottom_right_x, \n",
    "                            images.yolobox_bottom_right_y, \n",
    "                            images.image_path, \n",
    "                            listings.brand\n",
    "                        FROM images \n",
    "                        JOIN listings ON listings.id = images.listing_id\n",
    "                        WHERE \n",
    "                            listings.countrycode = 'B' \"\"\")\n",
    "labeled_data = pd.DataFrame(tags).fillna(-1)\n",
    "labeled_data = bbox_to_ints(labeled_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data[\"image_path\"] = labeled_data[\"image_path\"].apply(lambda x: x.replace('\\\\', '/'))\n",
    "labeled_data[\"abs_image_path\"]= basedir + '/' + labeled_data[\"image_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1354804"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labeled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand_encoder = LabelEncoder()\n",
    "labeled_data['brand'] = brand_encoder.fit_transform(labeled_data['brand'])  # Encode labels\n",
    "num_classes = len(brand_encoder.classes_)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data generator for online learning\n",
    "class DataGenerator:\n",
    "    def __init__(self, dataframe, batch_size, target_size, use_bbox):\n",
    "        self.dataframe = dataframe\n",
    "        self.batch_size = batch_size\n",
    "        self.target_size = target_size\n",
    "        self.usebbox = use_bbox\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.dataframe) / self.batch_size))\n",
    "\n",
    "    def __iter__(self):\n",
    "        for start in range(0, len(self.dataframe), self.batch_size):\n",
    "            end = min(start + self.batch_size, len(self.dataframe))\n",
    "            batch_data = self.dataframe.iloc[start:end]\n",
    "            \n",
    "            images = []\n",
    "            labels = []\n",
    "            for _, row in batch_data.iterrows():\n",
    "                img_path = row['abs_image_path']\n",
    "                label = row['brand']\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "                # TODO add the bounding box here!\n",
    "                x1, y1, x2, y2 = row['yolobox_top_left_x'], row['yolobox_top_left_y'], row['yolobox_bottom_right_x'], row['yolobox_bottom_right_y']\n",
    "                if self.usebbox and x1 != -1:\n",
    "                    #TODO implement bbox\n",
    "                    img = img[y1:y2, x1:x2]\n",
    "\n",
    "                # Load and preprocess the image\n",
    "                img = img.resize(self.target_size)\n",
    "                img = preprocess_input(np.array(img))  # Normalize for ResNet\n",
    "                images.append(img)\n",
    "                labels.append(label)\n",
    "            \n",
    "            images = np.array(images)\n",
    "            labels = to_categorical(labels, num_classes=num_classes)\n",
    "            yield images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-10 12:56:38.290155: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 102760448 exceeds 10% of free system memory.\n",
      "2025-01-10 12:56:38.331218: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 102760448 exceeds 10% of free system memory.\n",
      "2025-01-10 12:56:38.349667: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 102760448 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the data generator\n",
    "batch_size = 64\n",
    "target_size = (224, 224)\n",
    "data_gen = DataGenerator(labeled_data, batch_size, target_size, use_bbox)\n",
    "\n",
    "# Define the model (transfer learning using ResNet50)\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False  # Freeze the base model\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unrecognized data type: x=<__main__.DataGenerator object at 0x70f096d9b8d0> (of type <class '__main__.DataGenerator'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m steps_per_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(labeled_data) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m batch_size\n\u001b[1;32m      3\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/automotive_project/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Documents/automotive_project/lib/python3.11/site-packages/keras/src/trainers/data_adapters/__init__.py:125\u001b[0m, in \u001b[0;36mget_data_adapter\u001b[0;34m(x, y, sample_weight, batch_size, steps_per_epoch, shuffle, class_weight)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m GeneratorDataAdapter(x)\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# TODO: should we warn or not?\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;66;03m# warnings.warn(\u001b[39;00m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m#     \"`shuffle=True` was passed, but will be ignored since the \"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized data type: x=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Unrecognized data type: x=<__main__.DataGenerator object at 0x70f096d9b8d0> (of type <class '__main__.DataGenerator'>)"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model using online learning\n",
    "steps_per_epoch = len(labeled_data) // batch_size\n",
    "epochs = 5\n",
    "model.fit(\n",
    "    data_gen,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=epochs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the model\n",
    "model.save('online_model.h5')\n",
    "print(\"Training complete and model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old code below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preprocess labeled and unlabeled data\n",
    "labeled_images = load_data(labeled_data, use_bounding_boxes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_binary, X_test_binary, y_train_binary, y_test_binary = train_test_split(labeled_images, binary_labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train binary classifier\n",
    "binary_model.fit(X_train_binary, y_train_binary, epochs=10, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate binary classifier\n",
    "binary_loss, binary_accuracy = binary_model.evaluate(X_test_binary, y_test_binary)\n",
    "print(f\"Binary Classifier - Loss: {binary_loss}, Accuracy: {binary_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cutoff_point = 0.5\n",
    "# Predict non-crappy images\n",
    "binary_predictions_unlabeled = binary_model.predict(unlabeled_images)\n",
    "non_crappy_indices = np.where(binary_predictions_unlabeled < binary_cutoff_point)[0]\n",
    "non_crappy_images = unlabeled_images[non_crappy_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    x= range(len(binary_predictions_unlabeled)), \n",
    "    y = binary_predictions_unlabeled, \n",
    "    marker='.'\n",
    "    )\n",
    "plt.hlines(binary_cutoff_point, xmin=0, xmax=len(binary_predictions_unlabeled), color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare angle labels\n",
    "not_crappy_mask = labels != \"crappy\"\n",
    "angle_labels = labels[not_crappy_mask]\n",
    "angle_images = labeled_images[not_crappy_mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label_encoder = LabelEncoder()\n",
    "angle_labels_encoded = label_encoder.fit_transform(angle_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train angle classifier\n",
    "X_train_angle, X_test_angle, y_train_angle, y_test_angle = train_test_split(angle_images, angle_labels_encoded, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "angle_model.fit(X_train_angle, y_train_angle, epochs=10, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate angle classifier\n",
    "angle_loss, angle_accuracy = angle_model.evaluate(X_test_angle, y_test_angle)\n",
    "print(f\"Angle Classifier - Loss: {angle_loss}, Accuracy: {angle_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize a confusion matrix: \n",
    "y_test_predictions = angle_model.predict(X_test_angle)\n",
    "y_test_prediction_labels = np.argmax(y_test_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_decoded = label_encoder.inverse_transform(range(8))\n",
    "labels_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_on_y_test = pd.DataFrame(\n",
    "    {\n",
    "        'actuals': y_test_angle,\n",
    "        'predicts': y_test_prediction_labels\n",
    "    }\n",
    ")\n",
    "\n",
    "#confusion_on_y_test.sample(5)\n",
    "cm = confusion_matrix(confusion_on_y_test['actuals'], confusion_on_y_test['predicts'], labels=range(8))\n",
    "\n",
    "# Display confusion matrix using matplotlib\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels_decoded)\n",
    "disp.plot(ax=ax, cmap='Blues', colorbar=True)\n",
    "\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"Actual Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predict angles for non-crappy images\n",
    "predicted_angles = angle_model.predict(non_crappy_images)\n",
    "predicted_labels = label_encoder.inverse_transform(np.argmax(predicted_angles, axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random_unlabled_data = unlabeled_data.sample(200)\n",
    "random_unlabled_data[\"predicted_label\"] = \"crappy\"\n",
    "random_unlabled_data.iloc[non_crappy_indices, random_unlabled_data.columns.get_loc(\"predicted_label\")] = predicted_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_unlabled_data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "automotive_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
